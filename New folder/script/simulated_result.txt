LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 1
# batch size: 1
Epoch [10/500], Loss: 0.5111
Epoch [20/500], Loss: 0.5004
Epoch [30/500], Loss: 0.4960
Epoch [40/500], Loss: 0.5068
Epoch [50/500], Loss: 0.3996
Epoch [60/500], Loss: 0.8967
Epoch [70/500], Loss: 0.4279
Epoch [80/500], Loss: 2.5286
Epoch [90/500], Loss: 0.5079
Epoch [100/500], Loss: 1.4394
Epoch [110/500], Loss: 0.2979
Epoch [120/500], Loss: 0.4960
Epoch [130/500], Loss: 0.5027
Epoch [140/500], Loss: 3.7644
Epoch [150/500], Loss: 0.2979
Epoch [160/500], Loss: 0.2269
Epoch [170/500], Loss: 0.5111
Epoch [180/500], Loss: 0.5103
Epoch [190/500], Loss: 3.9134
Epoch [200/500], Loss: 2.9619
Epoch [210/500], Loss: 0.5122
Epoch [220/500], Loss: 0.5110
Epoch [230/500], Loss: 0.4279
Epoch [240/500], Loss: 0.8967
Epoch [250/500], Loss: 0.5068
Epoch [260/500], Loss: 4.0124
Epoch [270/500], Loss: 3.9134
Epoch [280/500], Loss: 0.5027
Epoch [290/500], Loss: 0.5079
Epoch [300/500], Loss: 0.5106
Epoch [310/500], Loss: 0.0651
Epoch [320/500], Loss: 0.5068
Epoch [330/500], Loss: 0.0119
Epoch [340/500], Loss: 0.5122
Epoch [350/500], Loss: 0.4693
Epoch [360/500], Loss: 1.4394
Epoch [370/500], Loss: 0.0119
Epoch [380/500], Loss: 0.2979
Epoch [390/500], Loss: 0.5083
Epoch [400/500], Loss: 0.2269
Epoch [410/500], Loss: 0.4538
Epoch [420/500], Loss: 0.1639
Epoch [430/500], Loss: 3.7644
Epoch [440/500], Loss: 0.0274
Epoch [450/500], Loss: 3.3105
Epoch [460/500], Loss: 0.5004
Epoch [470/500], Loss: 0.5106
Epoch [480/500], Loss: 3.7644
Epoch [490/500], Loss: 0.0274
Epoch [500/500], Loss: 0.5083
test lost compare to input data
Test Loss: 1.0000
test lost compare to no_noise data
Test Loss: 1.0000
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 1
# batch size: 10
Epoch [10/500], Loss: nan
Epoch [20/500], Loss: nan
Epoch [30/500], Loss: nan
Epoch [40/500], Loss: nan
Epoch [50/500], Loss: nan
Epoch [60/500], Loss: nan
Epoch [70/500], Loss: nan
Epoch [80/500], Loss: nan
Epoch [90/500], Loss: nan
Epoch [100/500], Loss: nan
Epoch [110/500], Loss: nan
Epoch [120/500], Loss: nan
Epoch [130/500], Loss: nan
Epoch [140/500], Loss: nan
Epoch [150/500], Loss: nan
Epoch [160/500], Loss: nan
Epoch [170/500], Loss: nan
Epoch [180/500], Loss: nan
Epoch [190/500], Loss: nan
Epoch [200/500], Loss: nan
Epoch [210/500], Loss: nan
Epoch [220/500], Loss: nan
Epoch [230/500], Loss: nan
Epoch [240/500], Loss: nan
Epoch [250/500], Loss: nan
Epoch [260/500], Loss: nan
Epoch [270/500], Loss: nan
Epoch [280/500], Loss: nan
Epoch [290/500], Loss: nan
Epoch [300/500], Loss: nan
Epoch [310/500], Loss: nan
Epoch [320/500], Loss: nan
Epoch [330/500], Loss: nan
Epoch [340/500], Loss: nan
Epoch [350/500], Loss: nan
Epoch [360/500], Loss: nan
Epoch [370/500], Loss: nan
Epoch [380/500], Loss: nan
Epoch [390/500], Loss: nan
Epoch [400/500], Loss: nan
Epoch [410/500], Loss: nan
Epoch [420/500], Loss: nan
Epoch [430/500], Loss: nan
Epoch [440/500], Loss: nan
Epoch [450/500], Loss: nan
Epoch [460/500], Loss: nan
Epoch [470/500], Loss: nan
Epoch [480/500], Loss: nan
Epoch [490/500], Loss: nan
Epoch [500/500], Loss: nan
test lost compare to input data
Test Loss: nan
test lost compare to no_noise data
Test Loss: nan
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 1
# batch size: 100
Epoch [10/500], Loss: 0.9637
Epoch [20/500], Loss: 0.7874
Epoch [30/500], Loss: 0.6184
Epoch [40/500], Loss: 0.5976
Epoch [50/500], Loss: 0.5955
Epoch [60/500], Loss: 0.5958
Epoch [70/500], Loss: 0.5947
Epoch [80/500], Loss: 0.5944
Epoch [90/500], Loss: 0.5943
Epoch [100/500], Loss: 0.5943
Epoch [110/500], Loss: 0.5943
Epoch [120/500], Loss: 0.5943
Epoch [130/500], Loss: 0.5943
Epoch [140/500], Loss: 0.5943
Epoch [150/500], Loss: 0.5943
Epoch [160/500], Loss: 0.5943
Epoch [170/500], Loss: 0.5943
Epoch [180/500], Loss: 0.5943
Epoch [190/500], Loss: 0.5943
Epoch [200/500], Loss: 0.5943
Epoch [210/500], Loss: 0.5943
Epoch [220/500], Loss: 0.5943
Epoch [230/500], Loss: 0.5943
Epoch [240/500], Loss: 0.5943
Epoch [250/500], Loss: 0.5943
Epoch [260/500], Loss: 0.5943
Epoch [270/500], Loss: 0.5943
Epoch [280/500], Loss: 0.5943
Epoch [290/500], Loss: 0.5943
Epoch [300/500], Loss: 0.5943
Epoch [310/500], Loss: 0.5943
Epoch [320/500], Loss: 0.5943
Epoch [330/500], Loss: 0.5943
Epoch [340/500], Loss: 0.5943
Epoch [350/500], Loss: 0.5943
Epoch [360/500], Loss: 0.5943
Epoch [370/500], Loss: 0.5943
Epoch [380/500], Loss: 0.5943
Epoch [390/500], Loss: 0.5943
Epoch [400/500], Loss: 0.5943
Epoch [410/500], Loss: 0.5943
Epoch [420/500], Loss: 0.5943
Epoch [430/500], Loss: 0.5943
Epoch [440/500], Loss: 0.5943
Epoch [450/500], Loss: 0.5943
Epoch [460/500], Loss: 0.5943
Epoch [470/500], Loss: 0.5943
Epoch [480/500], Loss: 0.5943
Epoch [490/500], Loss: 0.5943
Epoch [500/500], Loss: 0.5943
test lost compare to input data
Test Loss: 0.5930
test lost compare to no_noise data
Test Loss: 0.5928
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.1
# batch size: 1
Epoch [10/500], Loss: 0.0036
Epoch [20/500], Loss: 0.0189
Epoch [30/500], Loss: 0.0149
Epoch [40/500], Loss: 0.0263
Epoch [50/500], Loss: 0.0272
Epoch [60/500], Loss: 0.0210
Epoch [70/500], Loss: 0.6012
Epoch [80/500], Loss: 0.5225
Epoch [90/500], Loss: 0.0147
Epoch [100/500], Loss: 4.0125
Epoch [110/500], Loss: 0.0013
Epoch [120/500], Loss: 3.7644
Epoch [130/500], Loss: 0.0088
Epoch [140/500], Loss: 0.0028
Epoch [150/500], Loss: 0.0093
Epoch [160/500], Loss: 1.4394
Epoch [170/500], Loss: 0.4538
Epoch [180/500], Loss: 0.0305
Epoch [190/500], Loss: 0.0103
Epoch [200/500], Loss: 0.0059
Epoch [210/500], Loss: 0.0028
Epoch [220/500], Loss: 3.9134
Epoch [230/500], Loss: 0.0050
Epoch [240/500], Loss: 0.0072
Epoch [250/500], Loss: 3.9134
Epoch [260/500], Loss: 0.8967
Epoch [270/500], Loss: 0.0065
Epoch [280/500], Loss: 0.0033
Epoch [290/500], Loss: 0.0394
Epoch [300/500], Loss: 4.0124
Epoch [310/500], Loss: 0.0158
Epoch [320/500], Loss: 3.7644
Epoch [330/500], Loss: 3.3105
Epoch [340/500], Loss: 0.0021
Epoch [350/500], Loss: 3.7644
Epoch [360/500], Loss: 2.0026
Epoch [370/500], Loss: 0.1913
Epoch [380/500], Loss: 0.0045
Epoch [390/500], Loss: 0.8967
Epoch [400/500], Loss: 0.0045
Epoch [410/500], Loss: 0.0090
Epoch [420/500], Loss: 0.0075
Epoch [430/500], Loss: 0.0056
Epoch [440/500], Loss: 0.0017
Epoch [450/500], Loss: 0.0062
Epoch [460/500], Loss: 3.5705
Epoch [470/500], Loss: 0.0056
Epoch [480/500], Loss: 0.0046
Epoch [490/500], Loss: 2.9619
Epoch [500/500], Loss: 0.0116
test lost compare to input data
Test Loss: 0.7302
test lost compare to no_noise data
Test Loss: 0.7301
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.1
# batch size: 10
Epoch [10/500], Loss: 0.0032
Epoch [20/500], Loss: 0.4428
Epoch [30/500], Loss: 0.6744
Epoch [40/500], Loss: 0.0092
Epoch [50/500], Loss: 0.0058
Epoch [60/500], Loss: 0.0020
Epoch [70/500], Loss: 0.0030
Epoch [80/500], Loss: 0.0165
Epoch [90/500], Loss: 0.3506
Epoch [100/500], Loss: 0.0022
Epoch [110/500], Loss: 1.0095
Epoch [120/500], Loss: 0.0050
Epoch [130/500], Loss: 0.0012
Epoch [140/500], Loss: 0.0163
Epoch [150/500], Loss: 0.0035
Epoch [160/500], Loss: 0.6280
Epoch [170/500], Loss: 0.0077
Epoch [180/500], Loss: 0.0048
Epoch [190/500], Loss: 0.0035
Epoch [200/500], Loss: 0.0083
Epoch [210/500], Loss: 0.0676
Epoch [220/500], Loss: 0.0035
Epoch [230/500], Loss: 0.0044
Epoch [240/500], Loss: 0.0026
Epoch [250/500], Loss: 0.0012
Epoch [260/500], Loss: 0.0419
Epoch [270/500], Loss: 0.0347
Epoch [280/500], Loss: 0.0031
Epoch [290/500], Loss: 0.3512
Epoch [300/500], Loss: 0.0343
Epoch [310/500], Loss: 0.0019
Epoch [320/500], Loss: 0.0031
Epoch [330/500], Loss: 0.0030
Epoch [340/500], Loss: 0.0026
Epoch [350/500], Loss: 0.0134
Epoch [360/500], Loss: 0.1752
Epoch [370/500], Loss: 0.0497
Epoch [380/500], Loss: 0.0019
Epoch [390/500], Loss: 0.0052
Epoch [400/500], Loss: 0.9593
Epoch [410/500], Loss: 0.0870
Epoch [420/500], Loss: 0.3610
Epoch [430/500], Loss: 0.0042
Epoch [440/500], Loss: 0.0077
Epoch [450/500], Loss: 0.0062
Epoch [460/500], Loss: 0.5224
Epoch [470/500], Loss: 0.0037
Epoch [480/500], Loss: 0.0023
Epoch [490/500], Loss: 0.0113
Epoch [500/500], Loss: 0.0036
test lost compare to input data
Test Loss: 0.1713
test lost compare to no_noise data
Test Loss: 0.1709
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.1
# batch size: 100
Epoch [10/500], Loss: 0.3235
Epoch [20/500], Loss: 0.1835
Epoch [30/500], Loss: 0.1808
Epoch [40/500], Loss: 0.1800
Epoch [50/500], Loss: 0.1798
Epoch [60/500], Loss: 0.1797
Epoch [70/500], Loss: 0.1797
Epoch [80/500], Loss: 0.1797
Epoch [90/500], Loss: 0.1797
Epoch [100/500], Loss: 0.1796
Epoch [110/500], Loss: 0.1796
Epoch [120/500], Loss: 0.1796
Epoch [130/500], Loss: 0.1796
Epoch [140/500], Loss: 0.1796
Epoch [150/500], Loss: 0.1796
Epoch [160/500], Loss: 0.1796
Epoch [170/500], Loss: 0.1796
Epoch [180/500], Loss: 0.1979
Epoch [190/500], Loss: 0.1764
Epoch [200/500], Loss: 0.1915
Epoch [210/500], Loss: 0.1913
Epoch [220/500], Loss: 0.1881
Epoch [230/500], Loss: 0.1807
Epoch [240/500], Loss: 0.1681
Epoch [250/500], Loss: 0.1608
Epoch [260/500], Loss: 0.1522
Epoch [270/500], Loss: 0.1488
Epoch [280/500], Loss: 0.1460
Epoch [290/500], Loss: 0.1439
Epoch [300/500], Loss: 0.1426
Epoch [310/500], Loss: 0.1430
Epoch [320/500], Loss: 0.1440
Epoch [330/500], Loss: 0.1418
Epoch [340/500], Loss: 0.1417
Epoch [350/500], Loss: 0.1414
Epoch [360/500], Loss: 0.1413
Epoch [370/500], Loss: 0.1412
Epoch [380/500], Loss: 0.1412
Epoch [390/500], Loss: 0.1411
Epoch [400/500], Loss: 0.1411
Epoch [410/500], Loss: 0.1412
Epoch [420/500], Loss: 0.1410
Epoch [430/500], Loss: 0.1410
Epoch [440/500], Loss: 0.1410
Epoch [450/500], Loss: 0.1409
Epoch [460/500], Loss: 0.1409
Epoch [470/500], Loss: 0.1409
Epoch [480/500], Loss: 0.1409
Epoch [490/500], Loss: 0.1409
Epoch [500/500], Loss: 0.1409
test lost compare to input data
Test Loss: 0.1406
test lost compare to no_noise data
Test Loss: 0.1405
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.01
# batch size: 1
Epoch [10/500], Loss: 0.0095
Epoch [20/500], Loss: 0.0165
Epoch [30/500], Loss: 0.7223
Epoch [40/500], Loss: 0.0026
Epoch [50/500], Loss: 0.0016
Epoch [60/500], Loss: 0.3525
Epoch [70/500], Loss: 0.0011
Epoch [80/500], Loss: 0.0011
Epoch [90/500], Loss: 0.0016
Epoch [100/500], Loss: 0.0011
Epoch [110/500], Loss: 0.0005
Epoch [120/500], Loss: 0.1072
Epoch [130/500], Loss: 0.0008
Epoch [140/500], Loss: 0.0008
Epoch [150/500], Loss: 0.1752
Epoch [160/500], Loss: 0.0008
Epoch [170/500], Loss: 0.0007
Epoch [180/500], Loss: 0.7935
Epoch [190/500], Loss: 1.0089
Epoch [200/500], Loss: 0.8861
Epoch [210/500], Loss: 0.0019
Epoch [220/500], Loss: 0.9593
Epoch [230/500], Loss: 0.0005
Epoch [240/500], Loss: 0.0058
Epoch [250/500], Loss: 0.9592
Epoch [260/500], Loss: 0.0277
Epoch [270/500], Loss: 0.0008
Epoch [280/500], Loss: 0.0051
Epoch [290/500], Loss: 0.0007
Epoch [300/500], Loss: 0.0007
Epoch [310/500], Loss: 0.0029
Epoch [320/500], Loss: 0.0035
Epoch [330/500], Loss: 0.0004
Epoch [340/500], Loss: 0.0014
Epoch [350/500], Loss: 0.0052
Epoch [360/500], Loss: 0.0006
Epoch [370/500], Loss: 0.0008
Epoch [380/500], Loss: 0.0008
Epoch [390/500], Loss: 0.0004
Epoch [400/500], Loss: 0.0007
Epoch [410/500], Loss: 0.0051
Epoch [420/500], Loss: 2.5286
Epoch [430/500], Loss: 0.0029
Epoch [440/500], Loss: 0.0004
Epoch [450/500], Loss: 0.0004
Epoch [460/500], Loss: 0.0008
Epoch [470/500], Loss: 4.0124
Epoch [480/500], Loss: 0.4538
Epoch [490/500], Loss: 0.1639
Epoch [500/500], Loss: 0.0006
test lost compare to input data
Test Loss: 0.7093
test lost compare to no_noise data
Test Loss: 0.7099
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.01
# batch size: 10
Epoch [10/500], Loss: 1.7109
Epoch [20/500], Loss: 0.0336
Epoch [30/500], Loss: 0.0080
Epoch [40/500], Loss: 0.0052
Epoch [50/500], Loss: 0.0115
Epoch [60/500], Loss: 0.0112
Epoch [70/500], Loss: 0.0374
Epoch [80/500], Loss: 0.0105
Epoch [90/500], Loss: 0.0031
Epoch [100/500], Loss: 0.0025
Epoch [110/500], Loss: 0.0023
Epoch [120/500], Loss: 0.0194
Epoch [130/500], Loss: 0.8970
Epoch [140/500], Loss: 0.0019
Epoch [150/500], Loss: 0.9684
Epoch [160/500], Loss: 0.0019
Epoch [170/500], Loss: 0.0018
Epoch [180/500], Loss: 0.0053
Epoch [190/500], Loss: 0.0022
Epoch [200/500], Loss: 0.0013
Epoch [210/500], Loss: 0.0015
Epoch [220/500], Loss: 0.0017
Epoch [230/500], Loss: 0.0016
Epoch [240/500], Loss: 0.0017
Epoch [250/500], Loss: 0.0010
Epoch [260/500], Loss: 0.0063
Epoch [270/500], Loss: 0.0055
Epoch [280/500], Loss: 0.0017
Epoch [290/500], Loss: 0.0037
Epoch [300/500], Loss: 0.0020
Epoch [310/500], Loss: 0.6760
Epoch [320/500], Loss: 0.8886
Epoch [330/500], Loss: 0.0013
Epoch [340/500], Loss: 0.9617
Epoch [350/500], Loss: 0.0031
Epoch [360/500], Loss: 0.0012
Epoch [370/500], Loss: 0.0011
Epoch [380/500], Loss: 0.0009
Epoch [390/500], Loss: 0.0011
Epoch [400/500], Loss: 0.0012
Epoch [410/500], Loss: 0.0424
Epoch [420/500], Loss: 0.0020
Epoch [430/500], Loss: 0.0010
Epoch [440/500], Loss: 0.0012
Epoch [450/500], Loss: 0.0009
Epoch [460/500], Loss: 0.0010
Epoch [470/500], Loss: 0.0006
Epoch [480/500], Loss: 0.0011
Epoch [490/500], Loss: 0.0048
Epoch [500/500], Loss: 0.0018
test lost compare to input data
Test Loss: 0.1333
test lost compare to no_noise data
Test Loss: 0.1337
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.01
# batch size: 100
Epoch [10/500], Loss: 0.7281
Epoch [20/500], Loss: 0.3856
Epoch [30/500], Loss: 0.2611
Epoch [40/500], Loss: 0.2159
Epoch [50/500], Loss: 0.1996
Epoch [60/500], Loss: 0.1922
Epoch [70/500], Loss: 0.1885
Epoch [80/500], Loss: 0.1864
Epoch [90/500], Loss: 0.1849
Epoch [100/500], Loss: 0.1838
Epoch [110/500], Loss: 0.1831
Epoch [120/500], Loss: 0.1826
Epoch [130/500], Loss: 0.1820
Epoch [140/500], Loss: 0.1815
Epoch [150/500], Loss: 0.1810
Epoch [160/500], Loss: 0.1807
Epoch [170/500], Loss: 0.1802
Epoch [180/500], Loss: 0.1799
Epoch [190/500], Loss: 0.1798
Epoch [200/500], Loss: 0.1795
Epoch [210/500], Loss: 0.1793
Epoch [220/500], Loss: 0.1788
Epoch [230/500], Loss: 0.1778
Epoch [240/500], Loss: 0.1712
Epoch [250/500], Loss: 0.1633
Epoch [260/500], Loss: 0.1617
Epoch [270/500], Loss: 0.1602
Epoch [280/500], Loss: 0.1589
Epoch [290/500], Loss: 0.1577
Epoch [300/500], Loss: 0.1567
Epoch [310/500], Loss: 0.1559
Epoch [320/500], Loss: 0.1554
Epoch [330/500], Loss: 0.2371
Epoch [340/500], Loss: 0.1832
Epoch [350/500], Loss: 0.1826
Epoch [360/500], Loss: 0.1793
Epoch [370/500], Loss: 0.1775
Epoch [380/500], Loss: 0.1742
Epoch [390/500], Loss: 0.1706
Epoch [400/500], Loss: 0.1628
Epoch [410/500], Loss: 0.1597
Epoch [420/500], Loss: 0.1585
Epoch [430/500], Loss: 0.1554
Epoch [440/500], Loss: 0.1548
Epoch [450/500], Loss: 0.1537
Epoch [460/500], Loss: 0.1527
Epoch [470/500], Loss: 0.1520
Epoch [480/500], Loss: 0.1515
Epoch [490/500], Loss: 0.1510
Epoch [500/500], Loss: 0.1506
test lost compare to input data
Test Loss: 0.1497
test lost compare to no_noise data
Test Loss: 0.1494
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.001
# batch size: 1
Epoch [10/500], Loss: 0.1466
Epoch [20/500], Loss: 0.8171
Epoch [30/500], Loss: 0.0065
Epoch [40/500], Loss: 0.0128
Epoch [50/500], Loss: 0.0710
Epoch [60/500], Loss: 0.3993
Epoch [70/500], Loss: 0.3305
Epoch [80/500], Loss: 0.0057
Epoch [90/500], Loss: 0.0239
Epoch [100/500], Loss: 1.0361
Epoch [110/500], Loss: 0.3653
Epoch [120/500], Loss: 0.0047
Epoch [130/500], Loss: 0.3517
Epoch [140/500], Loss: 0.0070
Epoch [150/500], Loss: 0.8979
Epoch [160/500], Loss: 0.0036
Epoch [170/500], Loss: 0.0030
Epoch [180/500], Loss: 0.0053
Epoch [190/500], Loss: 0.0034
Epoch [200/500], Loss: 0.0031
Epoch [210/500], Loss: 0.0033
Epoch [220/500], Loss: 0.0033
Epoch [230/500], Loss: 0.0315
Epoch [240/500], Loss: 0.0091
Epoch [250/500], Loss: 0.0103
Epoch [260/500], Loss: 0.0442
Epoch [270/500], Loss: 1.0159
Epoch [280/500], Loss: 0.0031
Epoch [290/500], Loss: 0.0031
Epoch [300/500], Loss: 0.1782
Epoch [310/500], Loss: 0.0030
Epoch [320/500], Loss: 0.0028
Epoch [330/500], Loss: 0.0026
Epoch [340/500], Loss: 0.0028
Epoch [350/500], Loss: 0.0028
Epoch [360/500], Loss: 0.0022
Epoch [370/500], Loss: 0.0021
Epoch [380/500], Loss: 0.8897
Epoch [390/500], Loss: 0.0430
Epoch [400/500], Loss: 0.0019
Epoch [410/500], Loss: 0.0025
Epoch [420/500], Loss: 0.0026
Epoch [430/500], Loss: 0.0025
Epoch [440/500], Loss: 0.5242
Epoch [450/500], Loss: 0.8882
Epoch [460/500], Loss: 1.0109
Epoch [470/500], Loss: 0.0014
Epoch [480/500], Loss: 0.0014
Epoch [490/500], Loss: 0.0021
Epoch [500/500], Loss: 0.5236
test lost compare to input data
Test Loss: 0.1390
test lost compare to no_noise data
Test Loss: 0.1389
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.001
# batch size: 10
Epoch [10/500], Loss: 0.4761
Epoch [20/500], Loss: 0.3339
Epoch [30/500], Loss: 3.2859
Epoch [40/500], Loss: 0.1540
Epoch [50/500], Loss: 0.1259
Epoch [60/500], Loss: 0.0896
Epoch [70/500], Loss: 0.0207
Epoch [80/500], Loss: 1.1459
Epoch [90/500], Loss: 0.0219
Epoch [100/500], Loss: 0.0121
Epoch [110/500], Loss: 0.0112
Epoch [120/500], Loss: 0.0096
Epoch [130/500], Loss: 0.0566
Epoch [140/500], Loss: 0.0089
Epoch [150/500], Loss: 0.0077
Epoch [160/500], Loss: 0.0102
Epoch [170/500], Loss: 0.0081
Epoch [180/500], Loss: 0.2428
Epoch [190/500], Loss: 0.9166
Epoch [200/500], Loss: 0.2450
Epoch [210/500], Loss: 0.0085
Epoch [220/500], Loss: 0.9914
Epoch [230/500], Loss: 0.0710
Epoch [240/500], Loss: 0.0077
Epoch [250/500], Loss: 0.4094
Epoch [260/500], Loss: 0.0073
Epoch [270/500], Loss: 0.0084
Epoch [280/500], Loss: 0.0048
Epoch [290/500], Loss: 0.3240
Epoch [300/500], Loss: 0.0903
Epoch [310/500], Loss: 0.0579
Epoch [320/500], Loss: 0.0078
Epoch [330/500], Loss: 0.0075
Epoch [340/500], Loss: 0.0065
Epoch [350/500], Loss: 0.0073
Epoch [360/500], Loss: 0.0072
Epoch [370/500], Loss: 0.2023
Epoch [380/500], Loss: 0.0191
Epoch [390/500], Loss: 0.0394
Epoch [400/500], Loss: 0.0055
Epoch [410/500], Loss: 0.8423
Epoch [420/500], Loss: 0.0566
Epoch [430/500], Loss: 0.0052
Epoch [440/500], Loss: 0.0184
Epoch [450/500], Loss: 0.0048
Epoch [460/500], Loss: 0.2661
Epoch [470/500], Loss: 0.1417
Epoch [480/500], Loss: 0.0058
Epoch [490/500], Loss: 0.1385
Epoch [500/500], Loss: 0.0074
test lost compare to input data
Test Loss: 0.1596
test lost compare to no_noise data
Test Loss: 0.1592
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.001
# batch size: 100
Epoch [10/500], Loss: 1.0413
Epoch [20/500], Loss: 1.0193
Epoch [30/500], Loss: 0.9904
Epoch [40/500], Loss: 0.9501
Epoch [50/500], Loss: 0.8939
Epoch [60/500], Loss: 0.8230
Epoch [70/500], Loss: 0.7532
Epoch [80/500], Loss: 0.6855
Epoch [90/500], Loss: 0.6204
Epoch [100/500], Loss: 0.5622
Epoch [110/500], Loss: 0.5148
Epoch [120/500], Loss: 0.4784
Epoch [130/500], Loss: 0.4505
Epoch [140/500], Loss: 0.4287
Epoch [150/500], Loss: 0.4110
Epoch [160/500], Loss: 0.3964
Epoch [170/500], Loss: 0.3839
Epoch [180/500], Loss: 0.3731
Epoch [190/500], Loss: 0.3637
Epoch [200/500], Loss: 0.3554
Epoch [210/500], Loss: 0.3480
Epoch [220/500], Loss: 0.3414
Epoch [230/500], Loss: 0.3355
Epoch [240/500], Loss: 0.3301
Epoch [250/500], Loss: 0.3252
Epoch [260/500], Loss: 0.3207
Epoch [270/500], Loss: 0.3165
Epoch [280/500], Loss: 0.3125
Epoch [290/500], Loss: 0.3085
Epoch [300/500], Loss: 0.3037
Epoch [310/500], Loss: 0.2975
Epoch [320/500], Loss: 0.2937
Epoch [330/500], Loss: 0.2905
Epoch [340/500], Loss: 0.2875
Epoch [350/500], Loss: 0.2847
Epoch [360/500], Loss: 0.2820
Epoch [370/500], Loss: 0.2793
Epoch [380/500], Loss: 0.2769
Epoch [390/500], Loss: 0.2747
Epoch [400/500], Loss: 0.2728
Epoch [410/500], Loss: 0.2711
Epoch [420/500], Loss: 0.2696
Epoch [430/500], Loss: 0.2681
Epoch [440/500], Loss: 0.2668
Epoch [450/500], Loss: 0.2656
Epoch [460/500], Loss: 0.2644
Epoch [470/500], Loss: 0.2633
Epoch [480/500], Loss: 0.2623
Epoch [490/500], Loss: 0.2614
Epoch [500/500], Loss: 0.2604
test lost compare to input data
Test Loss: 0.2561
test lost compare to no_noise data
Test Loss: 0.2558
LSTMAutoencoder(
  (encoder): LSTM(3, 12, num_layers=2, batch_first=True)
  (decoder): LSTM(12, 3, num_layers=2, batch_first=True)
)
+----------------------+------------+
|       Modules        | Parameters |
+----------------------+------------+
| encoder.weight_ih_l0 |    144     |
| encoder.weight_hh_l0 |    576     |
|  encoder.bias_ih_l0  |     48     |
|  encoder.bias_hh_l0  |     48     |
| encoder.weight_ih_l1 |    576     |
| encoder.weight_hh_l1 |    576     |
|  encoder.bias_ih_l1  |     48     |
|  encoder.bias_hh_l1  |     48     |
| decoder.weight_ih_l0 |    144     |
| decoder.weight_hh_l0 |     36     |
|  decoder.bias_ih_l0  |     12     |
|  decoder.bias_hh_l0  |     12     |
| decoder.weight_ih_l1 |     36     |
| decoder.weight_hh_l1 |     36     |
|  decoder.bias_ih_l1  |     12     |
|  decoder.bias_hh_l1  |     12     |
+----------------------+------------+
Total Trainable Params: 2364
#######start training######
# learning rate: 0.0001
# batch size: 1
Epoch [10/500], Loss: 0.3417